---
title: "Credit Risk Modeling"
author: "Jordan Kassof"
date: "December 21, 2015"
output: html_document
---

Today I want to explore a classic classification problem encountered in business; credit ratings/approvals. In particular we will be looking to model the quality of a loan prospect given a set of attributes about the loan and the applicant.  We will be using the German Credit dataset that comes with the `caret` package.

First let's load up our data get a grip on what we are looking at.

```{r, message = FALSE}
library(caret); data("GermanCredit")
```

Below is an excerpt from the UCI MAchine Learning Repository about this particular data set.

>Data from Dr. Hans Hofmann of the University of Hamburg.

> These data have two classes for the credit worthiness: good or bad. 
> There are predictors related to attributes, such as: checking account 
> status, duration, credit history, purpose of the loan, amount of the 
> loan, savings accounts or bonds, employment duration, Installment rate in percentage of disposable income, personal information, other 
> debtors/guarantors, residence duration, property, age, other installment 
> plans, housing, number of existing credits, job information, Number of people being liable to provide maintenance for, telephone, and foreign worker status.

This is a very important task in the financial services industry; understanding the risk in a loan portfolio is crucial to any lender's business model. Bad credit masquerading as good credit was one of the key drivers of the 2008 financial crisis.

# Exploratory Data Analysis

Getting a general feel for the relationships represented by a data set is a crucial first step in modeling. Looking at our list of variables, Age seems like as good a place as ever to start looks. Let's see what the age distribution of Good and Bad loans look like.

Below code produces a nice ggplot visualization of the Age (of applicant), Duration (of loan) and Amount (of loan) broken out by the classification of the loan.

```{r, plotting age dists, warning = FALSE, fig.align = 'center', fig.height= 6}
library(gridExtra)
g1 <- ggplot(GermanCredit, aes(x = Class, y  = Age)) + 
  geom_violin(alpha = 0.5, color = "gray") + 
  geom_jitter(alpha = 0.5, aes(color = Class), position =   position_jitter(width = .2)) + coord_flip() + labs(x ="")  +
  theme(legend.position="none")

g2 <- ggplot(GermanCredit, aes(x = Class, y  = Duration)) + 
  geom_violin(alpha = 0.5, color = "gray") + 
  geom_jitter(alpha = 0.5, aes(color = Class), position =   position_jitter(width = .2)) + coord_flip() + labs(x ="") +
  theme(legend.position="none")

g3 <- ggplot(GermanCredit, aes(x = Class, y  = Amount)) + 
  geom_violin(alpha = 0.5, color = "gray") + 
  geom_jitter(alpha = 0.5, aes(color = Class), position =   position_jitter(width = .2)) + coord_flip() + labs(x ="") +
  theme(legend.position="none")

grid.arrange(g1, g2, g3, nrow = 3)
```

We can see that Bad loans appear to have a higher proportion of younger applicatants relative to Good loans. This isn't too surprising, we would expect older Applicants to be lower risk as they presumably have had more time to prepare financially and logistically to take on a line of credit.

# Modeling

In this section of our exploration I will be developing a number of models to predict the class of a loan.  I will utilize various algorithms and R package implementations but in the end I will attempt to quantitatively measure how each performs.

An important first step of any data modeling project is establishing training and testing dadta. We build our models on our training data, totally blind to the testing piece of the data set.  Once we are satisfied with our perforamcne on our training data we can apply the model to the testing set to get an idea for the out-of-sample performance of our model. This is a crucial step to insure we haven't overfit our model to our training data.  

Below we split our data into 60% training and 40% testing.

```{r}
inTrain <- createDataPartition(GermanCredit$Class, p = 0.6, list = FALSE)
training <- GermanCredit[inTrain,]
testing <- GermanCredit[-inTrain,]
```

## CART Modeling

Classification and Regression Tree (CART) modeling is a popular standard because the results are easy to visualize and interpret and it does not require a lot of computing power to make a new prediction. Below I will grow a basic decision tree

```{r, CART model, fig.align='center', cache= TRUE}
set.seed(1223); library(rpart)
rpart.fit <- rpart(Class ~ ., data = training, method = 'class')
plot(rpart.fit, uniform = TRUE, main = 'Credit Approval Decision Tree')
text(rpart.fit, cex = .65, use.n = TRUE)

```

As you can see, we have a very simple set of rules that can lead us to a decision now.  This tree is a little messy and decision trees have a tendency to overfit your training data.  For this reason I am going to prune the tree by using a complexity factor that minimizes the cross-validation error.

The below code prunes the tree, plots the new tree and then builds a confusion matrix to test how well this model can predict the testing data.

```{r pruning tree, fig.align = 'center'}
pruned.rpart <- rpart::prune(rpart.fit, cp = 
                        rpart.fit$cptable[which.min(rpart.fit$cptable[, "xerror"]), "CP"])

plot(pruned.rpart, uniform = TRUE, main = 'Pruned Credit Approval Tree')
text(pruned.rpart, cex = .65, use.n = TRUE)

confusionMatrix(predict(pruned.rpart, newdata = testing, type = 'class'), testing$Class)
```

So we can see we  have a 75% accuracy, but accuracy is not always the most relevant or important statistical measure.  There are a number of measures related to binary classification, all of which have their time to shine pending on your field!  A succint table describing the various measurements is below.

![alt text](http://41.media.tumblr.com/tumblr_m2by0pnhQ51rqgwpio1_1280.png "Logo Title Text 1")

## Conditional Inference Trees

Conditional inference trees are another example of recursive partioning.  Utilizing a clever statistical approach, CI Trees have slightly different nodes than regular decision trees and they provide distributional properties at the end of the tree. 

```{r, party tree}
set.seed(1223); library(party)
cfit <- ctree(Class ~ ., data = training)
plot(cfit, cex = .8)

```


## Random Forests

Random Forest algorithms have risen to become major players in predictive analytics  and are a natural extension of decision trees. Decision trees have a tendancy to overfit their training data; random forests ameliorate this problem by growing many decision trees, each with a random subset of the available features.  The random forest uses the mode or mean of all of the individual decision trees to come to a final prediction.

Below I will implement a random forest model based on standard decision trees and a second random forest based on conditional inference trees.

```{r, random forest, cache = TRUE, message=FALSE, warning = FALSE}
library(doParallel)
cl<- makeCluster(detectCores())
registerDoParallel(cl)

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10)

rf.fit <- train(Class ~ ., data = training,
                 method = "rf",
                 trControl = fitControl)

# crf.fit <- cforest(Class ~ ., data = training)

rf.fit
```

A very useful feature of tree based modeling is that you can easily identify the most important variables.  There are regulations that require a lender to provide the specific reasons an applicant was turned down in certain situations. Let's see what our models show.

```{r, variable important}



```